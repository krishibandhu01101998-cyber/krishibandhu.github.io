#@title üöÄ One-click: Streamlit app + Roboflow + ngrok (Colab, white bg / black text)
import sys, subprocess, os, time, pathlib, getpass

# 0) Install runtime deps (quiet)
subprocess.check_call([sys.executable, "-m", "pip", "-q", "install",
                       "streamlit", "pyngrok==7.2.1", "plotly",
                       "pillow", "numpy", "pandas", "tensorflow",
                       "requests", "roboflow"])

# 1) Write your Streamlit app (NOTE: no %%writefile inside)
APP_PATH = "/content/streamlit_app.py"
code = r'''
import os, io, pickle, tempfile, requests, sys
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import tensorflow as tf
from PIL import Image, ImageDraw
import streamlit as st
import plotly.graph_objects as go

# =================== CONFIG ===================
IST = ZoneInfo("Asia/Kolkata")

# ThingSpeak channels
TS_ACTUAL_CHANNEL_ID = 3007544   # Actuals (fields 1..4)
TS_PRED_CHANNEL_ID   = 3068374   # Predicted (fields 1..4)
TS_RESULTS_TO_FETCH  = 96

FIELDS = {
    1: ("temperature",  "Temperature (¬∞C)"),
    2: ("humidity",     "Humidity (%)"),
    3: ("rainMmHr",     "Rain (mm/hr)"),
    4: ("soilMoisture", "Soil Moisture (%)"),
}
MODEL_DIR = "/content/models"
LOOKBACK  = 4  # adjust to match your LSTM

# --- Rice disease model (PASTE YOUR EXACT COLAB PATHS HERE) ---
RICE_MODEL_PATH  = "/content/best_model.keras"   # <- change to your path
RICE_LABELS_PATH = "/content/labels (3).txt"     # <- change to your path
RICE_IMG_SIZE    = (256, 256)
SHOW_DEBUG = False

# =================== ROBOFLOW (server-side only; never shown in UI) ===================
from roboflow import Roboflow
# Using your provided key/workspace/project/version:
RF_KEY = os.environ.get("ROBOFLOW_API_KEY", "yhffXQ6NGin9SpzaaCjI")
rf_model = None
try:
    rf = Roboflow(api_key=RF_KEY)
    project = rf.workspace("debarpita").project("plant-detection-xi9rv")
    rf_model = project.version(2).model
except Exception as e:
    rf_model = None
    print("Roboflow init error:", e, file=sys.stderr)

ROBOFLOW_CONFIDENCE = 40
ROBOFLOW_OVERLAP    = 30

# =================== HELPERS ===================
def ts_fetch_channel(channel_id: int, results: int) -> Dict:
    url = f"https://api.thingspeak.com/channels/{channel_id}/feeds.json"
    r = requests.get(url, params={"results": results}, timeout=60)
    r.raise_for_status()
    return r.json()

def ts_channel_to_df(channel_json: Dict, prefix: str) -> pd.DataFrame:
    feeds = channel_json.get("feeds", [])
    rows = []
    for f in feeds:
        try:
            ts_ist = pd.to_datetime(f.get("created_at"), utc=True).tz_convert(IST)
        except Exception:
            continue
        row = {"Timestamp": ts_ist}
        for i in range(1, 9):
            v = f.get(f"field{i}")
            try:
                row[f"{prefix}_field{i}"] = float(v) if v is not None else np.nan
            except Exception:
                row[f"{prefix}_field{i}"] = np.nan
        rows.append(row)
    df = pd.DataFrame(rows)
    if df.empty:
        return df
    return df.dropna(subset=["Timestamp"]).sort_values("Timestamp").reset_index(drop=True)

def merge_actual_pred_df(df_act: pd.DataFrame, df_pred: pd.DataFrame) -> pd.DataFrame:
    if df_act.empty and df_pred.empty:
        return pd.DataFrame()
    # ‚úÖ correct usage
    df = pd.merge(df_act, df_pred, on="Timestamp", how="outer").sort_values("Timestamp").reset_index(drop=True)
    return df

# ---------- Model loading (server-side from /content/models) with cache ----------
@st.cache_resource(show_spinner=False)
def load_all_models() -> Dict[str, Tuple[tf.keras.Model, object]]:
    out = {}
    for idx, (tag, _label) in FIELDS.items():
        h5_path  = os.path.join(MODEL_DIR, f"{tag}.h5")
        pkl_path = os.path.join(MODEL_DIR, f"{tag}_scaler.pkl")
        if os.path.exists(h5_path) and os.path.exists(pkl_path):
            try:
                model = tf.keras.models.load_model(h5_path, compile=False)
                with open(pkl_path, "rb") as f:
                    scaler = pickle.load(f)
                out[tag] = (model, scaler)
            except Exception as e:
                print(f"[models] {tag} load error: {e}", file=sys.stderr)
        else:
            print(f"[models] {tag} missing: {h5_path}, {pkl_path}", file=sys.stderr)
    return out

def ensure_series(values: List[float], lookback: int) -> List[float]:
    vals = [v for v in values if v is not None and not np.isnan(v)]
    if not vals:
        return []
    if len(vals) < lookback:
        pad = [vals[-1]] * (lookback - len(vals))
        return vals + pad
    return vals

def predict_series_lenient(values: List[float], model, scaler, lookback: int, n_points: int) -> List[Optional[float]]:
    preds = [None] * n_points
    vals = [float(v) if v is not None else np.nan for v in values]
    s = pd.Series(vals).replace([np.inf, -np.inf], np.nan).ffill().bfill()
    base = s.tolist()
    if len(base) == 0:
        return preds
    if len(base) < lookback:
        window = ensure_series(base, lookback)[-lookback:]
        arr = np.array(window, dtype=np.float32).reshape(-1,1)
        Xs  = scaler.transform(arr)[None, ...]
        y_scaled = model.predict(Xs, verbose=0)
        y = float(scaler.inverse_transform(y_scaled.reshape(-1,1)).ravel()[0])
        preds[-1] = y
        return preds
    arr = np.array(base, dtype=np.float32).reshape(-1,1)
    arr_scaled = scaler.transform(arr)
    for t in range(lookback, n_points):
        X = arr_scaled[t-lookback:t].reshape(1, lookback, 1)
        y_scaled = model.predict(X, verbose=0)
        y = float(scaler.inverse_transform(y_scaled.reshape(-1,1)).ravel()[0])
        preds[t] = y
    return preds

def latest_pair(df: pd.DataFrame, idx: int) -> Tuple[Optional[float], Optional[float]]:
    if df.empty: return None, None
    a = df.get(f"actual_field{idx}", pd.Series(dtype=float)).dropna()
    p_ext = df.get(f"pred_field{idx}", pd.Series(dtype=float))
    p_loc = df.get(f"pred_local_{idx}", pd.Series(dtype=float))
    a_val = float(a.iloc[-1]) if not a.empty else None
    p_val = None
    if p_ext is not None:
        p_ext = pd.Series(p_ext).dropna()
        if not p_ext.empty: p_val = float(p_ext.iloc[-1])
    if p_val is None and p_loc is not None:
        p_loc = pd.Series(p_loc).dropna()
        if not p_loc.empty: p_val = float(p_loc.iloc[-1])
    return a_val, p_val

def latest_pref(df: pd.DataFrame, idx: int) -> Optional[float]:
    if df.empty: return None
    a = df.get(f"actual_field{idx}", pd.Series(dtype=float)).dropna()
    if not a.empty: return float(a.iloc[-1])
    p = df.get(f"pred_field{idx}", pd.Series(dtype=float))
    if p is not None:
        p = pd.Series(p).dropna()
        if not p.empty: return float(p.iloc[-1])
    pl = df.get(f"pred_local_{idx}", pd.Series(dtype=float))
    if pl is not None:
        pl = pd.Series(pl).dropna()
        if not pl.empty: return float(pl.iloc[-1])
    return None

def build_recommendations(T: float, H: float, R: float, S: float, lang: str) -> List[str]:
    lines = []
    if S < 35 and R < 1:
        lines.append({"en":"Soil moisture is low. Irrigate now (short cycle).",
                      "hi":"‡§Æ‡•É‡§¶‡§æ ‡§®‡§Æ‡•Ä ‡§ï‡§Æ ‡§π‡•à‡•§ ‡§Ö‡§≠‡•Ä ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§ï‡§∞‡•á‡§Ç (‡§ï‡§Æ ‡§Ö‡§µ‡§ß‡§ø)‡•§",
                      "bn":"‡¶Æ‡¶æ‡¶ü‡¶ø‡¶∞ ‡¶Ü‡¶∞‡ßç‡¶¶‡ßç‡¶∞‡¶§‡¶æ ‡¶ï‡¶Æ‡•§ ‡¶è‡¶ñ‡¶®‡¶á ‡¶∏‡ßç‡¶¨‡¶≤‡ßç‡¶™ ‡¶∏‡¶Æ‡¶Ø‡¶º‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡ßá‡¶ö ‡¶¶‡¶ø‡¶®‡•§"}[lang])
    if R >= 2:
        lines.append({"en":"Rain is significant. Avoid irrigation; defer fertilizer.",
                      "hi":"‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§π‡•à‡•§ ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§® ‡§ï‡§∞‡•á‡§Ç; ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï ‡§¨‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§Ç‡•§",
                      "bn":"‡¶¨‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø ‡¶Ø‡¶•‡ßá‡¶∑‡ßç‡¶ü‡•§ ‡¶∏‡ßá‡¶ö ‡¶¶‡ßá‡¶¨‡ßá‡¶® ‡¶®‡¶æ; ‡¶∏‡¶æ‡¶∞ ‡¶™‡¶∞‡ßá ‡¶¶‡¶ø‡¶®‡•§"}[lang])
    if T > 35 and H < 30:
        lines.append({"en":"High heat + low humidity. Prefer evening irrigation; provide shade.",
                      "hi":"‡§â‡§ö‡•ç‡§ö ‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§µ ‡§ï‡§Æ ‡§Ü‡§∞‡•ç‡§¶‡•ç‡§∞‡§§‡§æ‡•§ ‡§∏‡§Ç‡§ß‡•ç‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§ï‡§∞‡•á‡§Ç; ‡§õ‡§æ‡§Ø‡§æ ‡§¶‡•á‡§Ç‡•§",
                      "bn":"‡¶â‡¶ö‡ßç‡¶ö ‡¶§‡¶æ‡¶™‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶ì ‡¶ï‡¶Æ ‡¶Ü‡¶∞‡ßç‡¶¶‡ßç‡¶∞‡¶§‡¶æ‡•§ ‡¶∏‡¶®‡ßç‡¶ß‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º ‡¶∏‡ßá‡¶ö ‡¶¶‡¶ø‡¶®; ‡¶õ‡¶æ‡¶Ø‡¶º‡¶æ ‡¶¶‡¶ø‡¶®‡•§"}[lang])
    if S > 80:
        lines.append({"en":"Soil saturated. Improve drainage; pause irrigation.",
                      "hi":"‡§Æ‡•É‡§¶‡§æ ‡§∏‡§Ç‡§§‡•É‡§™‡•ç‡§§‡•§ ‡§®‡§ø‡§ï‡§æ‡§∏ ‡§∏‡•Å‡§ß‡§æ‡§∞‡•á‡§Ç; ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§∞‡•ã‡§ï‡•á‡§Ç‡•§",
                      "bn":"‡¶Æ‡¶æ‡¶ü‡¶ø ‡¶∏‡ßç‡¶Ø‡¶æ‡¶ö‡ßÅ‡¶∞‡ßá‡¶ü‡ßá‡¶°‡•§ ‡¶®‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∂‡¶® ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶®; ‡¶∏‡ßá‡¶ö ‡¶¨‡¶®‡ßç‡¶ß ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®‡•§"}[lang])
    if not lines:
        lines.append({"en":"Conditions normal. Continue routine schedule.",
                      "hi":"‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø‡•§ ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§ú‡§æ‡§∞‡•Ä ‡§∞‡§ñ‡•á‡§Ç‡•§",
                      "bn":"‡¶™‡¶∞‡¶ø‡¶∏‡ßç‡¶•‡¶ø‡¶§‡¶ø ‡¶∏‡ßç‡¶¨‡¶æ‡¶≠‡¶æ‡¶¨‡¶ø‡¶ï‡•§ ‡¶∞‡ßÅ‡¶ü‡¶ø‡¶® ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶ö‡¶≤‡ßÅ‡¶®‡•§"}[lang])
    return lines

# ---------- Roboflow detection ----------
def rf_predict_image_to_counts(image: Image.Image) -> Tuple[Image.Image, Dict[str,int]]:
    if rf_model is None:
        raise RuntimeError("Roboflow not configured on the server.")
    with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
        image.save(tmp.name, format="JPEG", quality=95)
        res = rf_model.predict(tmp.name, confidence=ROBOFLOW_CONFIDENCE, overlap=ROBOFLOW_OVERLAP).json()
    preds = res.get("predictions", [])
    draw = ImageDraw.Draw(image)
    colors = {"healthy": (0,200,0), "partially healthy": (255,165,0), "unhealthy": (255,0,0)}
    counts = {}
    for p in preds:
        cls = p.get("class") or "unknown"
        x,y,w,h = float(p["x"]), float(p["y"]), float(p["width"]), float(p["height"])
        x1,y1 = int(x-w/2), int(y-h/2); x2,y2 = int(x+w/2), int(y+h/2)
        col = colors.get(cls, (255,255,255))
        draw.rectangle([x1,y1,x2,y2], outline=col, width=3)
        tag = cls
        tw = int(7.0*len(tag)) + 10
        draw.rectangle([x1, max(0,y1-20), x1+tw, y1], fill=col)
        draw.text((x1+5, max(0,y1-18)), tag, fill=(255,255,255))
        counts[cls] = counts.get(cls, 0)+1
    return image, counts

def verdict_from_counts(counts: Dict[str,int], lang: str) -> str:
    h  = counts.get("healthy", 0)
    ph = counts.get("partially healthy", 0)
    uh = counts.get("unhealthy", 0)
    if uh > 0 and uh >= max(h, ph): return {"en":"Unhealthy","hi":"‡§Ö‡§∏‡•ç‡§µ‡§∏‡•ç‡§•","bn":"‡¶Ö‡¶∏‡ßÅ‡¶∏‡ßç‡¶•"}[lang]
    if ph > 0 and ph >= max(h, uh): return {"en":"Partially Healthy","hi":"‡§Ü‡§Ç‡§∂‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§∏‡•ç‡§µ‡§∏‡•ç‡§•","bn":"‡¶Ü‡¶Ç‡¶∂‡¶ø‡¶ï ‡¶∏‡ßÅ‡¶∏‡ßç‡¶•"}[lang]
    if h  > 0:                     return {"en":"Healthy","hi":"‡§∏‡•ç‡§µ‡§∏‡•ç‡§•","bn":"‡¶∏‡ßÅ‡¶∏‡ßç‡¶•"}[lang]
    return {"en":"Unknown","hi":"‡§Ö‡§ú‡•ç‡§û‡§æ‡§§","bn":"‡¶Ö‡¶ú‡¶æ‡¶®‡¶æ"}[lang]

# =================== UI TEXTS ===================
LANGS = {"English":"en", "‡§π‡§ø‡§®‡•ç‡§¶‡•Ä":"hi", "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ":"bn"}
TEXTS = {
    "title": {"en":"Krishibandhu Field Dashboard","hi":"‡§ï‡•É‡§∑‡§ø‡§¨‡§Ç‡§ß‡•Å ‡§´‡•Ä‡§≤‡•ç‡§° ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§°","bn":"‡¶ï‡ßÉ‡¶∑‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡ßÅ ‡¶´‡¶ø‡¶≤‡ßç‡¶° ‡¶°‡ßç‡¶Ø‡¶æ‡¶∂‡¶¨‡ßã‡¶∞‡ßç‡¶°"},
    "last_updated":{"en":"Last updated (IST)","hi":"‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§Ö‡§¶‡•ç‡§Ø‡§§‡§® (IST)","bn":"‡¶∂‡ßá‡¶∑ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü (IST)"},
    "header_all":{"en":"Latest (IST) ‚Äî Actual / Predicted","hi":"‡§®‡§µ‡•Ä‡§®‡§§‡§Æ (IST) ‚Äî Actual / Predicted","bn":"‡¶∏‡¶∞‡ßç‡¶¨‡¶∂‡ßá‡¶∑ (IST) ‚Äî Actual / Predicted"},
    "charts":{"en":"Actual vs Predicted","hi":"‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§¨‡§®‡§æ‡§Æ ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®‡§ø‡§§","bn":"‡¶¨‡¶æ‡¶∏‡ßç‡¶§‡¶¨ ‡¶¨‡¶®‡¶æ‡¶Æ ‡¶™‡ßÇ‡¶∞‡ßç‡¶¨‡¶æ‡¶≠‡¶æ‡¶∏"},
    "download_all":{"en":"Download merged CSV (Actual+Pred)","hi":"‡§Æ‡§∞‡•ç‡§ú‡§º‡•ç‡§° CSV ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° (Actual+Pred)","bn":"‡¶Æ‡¶æ‡¶∞‡ßç‡¶ú‡¶° CSV ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° (Actual+Pred)"},
    "recommendations":{"en":"Recommendations","hi":"‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂‡•á‡§Ç","bn":"‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡¶æ‡¶¨‡¶®‡¶æ"},
    "plant":{"en":"Plant Health (Upload / Click ‚Üí Detect)","hi":"‡§™‡•å‡§ß‡•á ‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø (‡§Ö‡§™‡§≤‡•ã‡§° / ‡§ï‡•à‡§Æ‡§∞‡§æ ‚Üí ‡§°‡§ø‡§ü‡•á‡§ï‡•ç‡§ü)","bn":"‡¶â‡¶¶‡ßç‡¶≠‡¶ø‡¶¶‡ßá‡¶∞ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø (‡¶Ü‡¶™‡¶≤‡ßã‡¶° / ‡¶ï‡ßç‡¶Ø‡¶æ‡¶Æ‡ßá‡¶∞‡¶æ ‚Üí ‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡ßç‡¶ü)"},
    "upload_img":{"en":"Upload plant image","hi":"‡§™‡•å‡§ß‡•á ‡§ï‡•Ä ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§Ö‡§™‡¶≤‡ßã‡§° ‡§ï‡§∞‡•á‡§Ç","bn":"‡¶ó‡¶æ‡¶õ‡ßá‡¶∞ ‡¶õ‡¶¨‡¶ø ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®"},
    "click_img":{"en":"Or click a photo (webcam)","hi":"‡§Ø‡§æ ‡§´‡•ã‡§ü‡•ã ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞‡•á‡§Ç (‡§µ‡•á‡§¨‡§ï‡•à‡§Æ)","bn":"‡¶Ö‡¶•‡¶¨‡¶æ ‡¶õ‡¶¨‡¶ø ‡¶§‡ßÅ‡¶≤‡ßÅ‡¶® (‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶ï‡ßç‡¶Ø‡¶æ‡¶Æ)"},
    "run":{"en":"Run Detection","hi":"‡§°‡§ø‡§ü‡•á‡§ï‡•ç‡§∂‡§® ‡§ö‡§≤‡§æ‡§è‡§Å","bn":"‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡¶∂‡¶® ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®"},
    "counts":{"en":"Detected counts","hi":"‡§°‡§ø‡§ü‡•á‡§ï‡•ç‡§ü‡•á‡§° ‡§ó‡§ø‡§®‡§§‡•Ä","bn":"‡¶∏‡¶®‡¶æ‡¶ï‡ßç‡¶§ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ"},
    "verdict":{"en":"Health verdict","hi":"‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑","bn":"‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∞‡¶æ‡¶Ø‡¶º"},
    "rice_title":{"en":"Rice Leaf Disease Detection","hi":"‡§ß‡§æ‡§® ‡§™‡§§‡•ç‡§§‡•Ä ‡§∞‡•ã‡§ó ‡§™‡§π‡§ö‡§æ‡§®","bn":"‡¶ß‡¶æ‡¶®‡ßá‡¶∞ ‡¶™‡¶æ‡¶§‡¶æ ‡¶∞‡ßã‡¶ó ‡¶∏‡¶®‡¶æ‡¶ï‡ßç‡¶§‡¶ï‡¶∞‡¶£"},
    "rice_upload":{"en":"Upload a rice leaf image","hi":"‡§ß‡§æ‡§® ‡§ï‡•Ä ‡§™‡§§‡•ç‡§§‡•Ä ‡§ï‡•Ä ‡§õ‡§µ‡§ø ‡§Ö‡§™‡¶≤‡ßã‡§° ‡§ï‡§∞‡•á‡§Ç","bn":"‡¶ß‡¶æ‡¶®‡ßá‡¶∞ ‡¶™‡¶æ‡¶§‡¶æ‡¶∞ ‡¶õ‡¶¨‡¶ø ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®"},
    "rice_run":{"en":"Classify Disease","hi":"‡§∞‡•ã‡§ó ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡•á‡§Ç","bn":"‡¶∞‡ßã‡¶ó ‡¶∂‡ßç‡¶∞‡ßá‡¶£‡ßÄ‡¶ï‡¶∞‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®"},
}

# =================== PAGE SETUP & LIGHT THEME (white bg, black text) ===================
st.set_page_config(page_title="Krishibandhu Dashboard", layout="wide")
st.markdown("""
<style>
/* Global light theme */
html, body, .stApp { background:#ffffff !important; color:#000000 !important; }

/* Main page container */
.block-container {
  background: rgba(255,255,255,0.98);
  padding: 1rem 1.2rem;
  border-radius: 14px;
  box-shadow: 0 6px 24px rgba(0,0,0,0.06);
  color:#000 !important;
}

/* Force common text to black */
.stMarkdown, .stMarkdown p, .stCaption, .caption, label,
[data-testid="stSidebar"] *, [data-testid="stMetricValue"],
[data-testid="stMetricLabel"], [data-testid="stMetricDelta"],
.st-emotion-cache, .stText, .stTextInput, .stAlert, .stDataFrame,
[data-baseweb="select"] * { color:#000 !important; }

/* Sidebar */
[data-testid="stSidebar"] {
  background:#f7f7f7 !important;
  border-right: 1px solid #e6e6e6;
}

/* Selectbox / inputs */
[data-testid="stSelectbox"] div[data-baseweb="select"] > div {
  background:#fff !important;
  color:#000 !important;
  border-radius:10px !important;
  border:1px solid #d0d0d0 !important;
}
[data-testid="stSelectbox"] svg { fill:#000 !important; }

/* Buttons / downloads */
.stButton > button, .stDownloadButton > button {
  background:#81c784 !important; /* soft green */
  color:#000 !important;
  border: 1px solid #5fb96b !important;
  border-radius:10px !important;
}
.stButton > button:hover, .stDownloadButton > button:hover {
  background:#66bb6a !important; color:#000 !important;
}

/* Metric cards */
[data-testid="stMetric"] {
  background:#ffffff;
  color:#000 !important;
  border-radius:12px;
  padding:10px 12px;
  border:1px solid #e0e0e0;
}

/* Plotly container */
.js-plotly-plot, .plot-container, .stPlotlyChart { background:transparent !important; }

/* Title */
.kb-title {
  color:#000 !important; font-weight:800 !important; line-height:1.25 !important;
  background: #fff; display:block; padding:12px 16px;
  border-radius:14px; box-shadow:0 4px 16px rgba(0,0,0,0.06); margin: 2px 0 8px 0;
  text-align:center; word-break:break-word; white-space:normal; overflow:visible; width:100%;
}

/* Verdict pill keeps white text for contrast */
.kb-verdict-pill, .kb-verdict-pill * {
  color:#fff !important;
  font-weight:700;
  display:inline-block;
  padding:6px 12px;
  border-radius:999px;
  line-height:1.2;
}
</style>
""", unsafe_allow_html=True)

# Language selector
lang_label = st.sidebar.selectbox("Language", list(LANGS.keys()), index=0)
LANG = {"English":"en", "‡§π‡§ø‡§®‡•ç‡§¶‡•Ä":"hi", "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ":"bn"}[lang_label]

# Title
st.markdown(f"<h1 class='kb-title'>{TEXTS['title'][LANG]}</h1>", unsafe_allow_html=True)

# ---- Fetch ThingSpeak
try:
    js_actual = ts_fetch_channel(TS_ACTUAL_CHANNEL_ID, TS_RESULTS_TO_FETCH)
    js_pred   = ts_fetch_channel(TS_PRED_CHANNEL_ID,   TS_RESULTS_TO_FETCH)
    df_act    = ts_channel_to_df(js_actual, "actual")
    df_pred   = ts_channel_to_df(js_pred,   "pred")
    df_merge  = merge_actual_pred_df(df_act, df_pred)
    st.caption(f"{TEXTS['last_updated'][LANG]}: {datetime.now(IST).strftime('%Y-%m-%d %H:%M:%S %Z')}")
except Exception as e:
    st.error(f"Failed to read ThingSpeak: {e}")
    df_merge = pd.DataFrame()

# ---- Optional local predictions
@st.cache_resource(show_spinner=False)
def _models():
    return load_all_models()
models = _models()
for idx in range(1,5):
    tag, _label = FIELDS[idx]
    a_col = f"actual_field{idx}"
    if df_merge.empty or a_col not in df_merge.columns:
        continue
    try:
        if tag not in models:
            print(f"[predict] {tag}: model not loaded; skipping", file=sys.stderr)
            continue
        p_col = f"pred_field{idx}"
        need_local = (p_col not in df_merge.columns) or pd.Series(df_merge.get(p_col)).isna().all()
        if not need_local:
            continue
        model, scaler = models[tag]
        vals = df_merge[a_col].astype(float).replace([np.inf, -np.inf], np.nan).tolist()
        preds = predict_series_lenient(vals, model, scaler, LOOKBACK, len(df_merge))
        df_merge[f"pred_local_{idx}"] = preds
    except Exception as e:
        print(f"[predict] {tag}: {e}", file=sys.stderr)

# ---- Headline metrics
st.subheader(TEXTS["header_all"][LANG])
row = st.columns(4)
labels = ["Temperature (¬∞C)","Rain (mm/hr)","Humidity (%)","Soil Moisture (%)"]
order  = [1,3,2,4]
for c, idx, lab in zip(row, order, labels):
    a, p = latest_pair(df_merge, idx)
    c.metric(lab, f"{a:.2f}" if a is not None else "--", delta=f"Pred {p:.2f}" if p is not None else "Pred --")

# ---- Charts
st.subheader(TEXTS["charts"][LANG])
cc = st.columns(2)

def style_axes(fig):
    fig.update_layout(
        template="none",
        height=380,
        margin=dict(l=20, r=20, t=50, b=100),
        paper_bgcolor="#ffffff",
        plot_bgcolor="#ffffff",
        font=dict(color="#000000"),
        legend=dict(
            bgcolor="rgba(255,255,255,0.95)",
            bordercolor="rgba(0,0,0,0.12)",
            borderwidth=1,
            font=dict(color="#000000")
        )
    )
    fig.update_xaxes(
        title_text="Time (IST)",
        title_standoff=16,
        tickformat="%H:%M",
        tickangle=-30,
        nticks=8,
        showline=True,
        linecolor="#000000",
        gridcolor="rgba(0,0,0,0.12)",
        zeroline=False,
        automargin=True
    )
    fig.update_yaxes(
        tickfont=dict(color="#000000"),
        titlefont=dict(color="#000000"),
        gridcolor="rgba(0,0,0,0.12)",
        showline=True,
        linecolor="#000000",
        zeroline=False,
        automargin=True
    )

for idx in range(1,5):
    tag, label = FIELDS[idx]
    if df_merge.empty:
        with cc[(idx-1)%2]:
            st.info(f"{label}: no data")
        continue

    pred_series = None
    if f"pred_field{idx}" in df_merge.columns and not pd.Series(df_merge[f"pred_field{idx}"]).isna().all():
        pred_series = df_merge[f"pred_field{idx}"]
    elif f"pred_local_{idx}" in df_merge.columns:
        pred_series = df_merge[f"pred_local_{idx}"]

    df_tidy = pd.DataFrame({
        "Timestamp": df_merge["Timestamp"].dt.tz_convert(IST),
        "Actual": df_merge.get(f"actual_field{idx}", pd.Series(dtype=float)),
        "Predicted": pred_series if pred_series is not None else pd.Series([None]*len(df_merge)),
    })

    with cc[(idx-1)%2]:
        fig = go.Figure()
        if df_tidy["Actual"].notna().any():
            fig.add_trace(go.Scatter(x=df_tidy["Timestamp"], y=df_tidy["Actual"], mode="lines", name="Actual"))
        if df_tidy["Predicted"].notna().any():
            fig.add_trace(go.Scatter(x=df_tidy["Timestamp"], y=df_tidy["Predicted"], mode="lines",
                                     name="Predicted", line=dict(dash="dash")))
        fig.update_layout(title=dict(text=label, y=0.98, x=0.5, xanchor="center", yanchor="top"))
        style_axes(fig)
        st.plotly_chart(fig, use_container_width=True)

# ---- CSV download (IST)
if not df_merge.empty:
    df_dl = df_merge.copy()
    df_dl["Timestamp"] = df_dl["Timestamp"].dt.tz_convert(IST).astype(str)
    keep_cols = (["Timestamp"] +
                 [f"actual_field{i}" for i in range(1,5)] +
                 [f"pred_field{i}" for i in range(1,5) if f"pred_field{i}" in df_merge.columns] +
                 [f"pred_local_{i}" for i in range(1,5) if f"pred_local_{i}" in df_merge.columns])
    existing = [c for c in keep_cols if c in df_dl.columns]
    st.download_button(TEXTS["download_all"][LANG], data=df_dl[existing].to_csv(index=False).encode("utf-8"),
                       file_name="thingspeak_actual_pred_IST.csv", mime="text/csv")

# ---- Recommendations
T_last = latest_pref(df_merge, 1) or 28.0
H_last = latest_pref(df_merge, 2) or 60.0
R_last = latest_pref(df_merge, 3) or 0.0
S_last = latest_pref(df_merge, 4) or 40.0

st.subheader(TEXTS["recommendations"][LANG])
for line in build_recommendations(T_last, H_last, R_last, S_last, LANG):
    st.markdown(f"- {line}")

# =================== PLANT HEALTH (Upload / Click ‚Üí Detect) ===================
st.subheader(TEXTS["plant"][LANG])

if "open_cam" not in st.session_state:
    st.session_state.open_cam = False

colL, colR = st.columns([0.55, 0.45])
with colL:
    uploaded_img = st.file_uploader(TEXTS["upload_img"][LANG], type=["jpg","jpeg","png"])

    c1, c2 = st.columns(2)
    with c1:
        if st.button("Click Photo"):
            st.session_state.open_cam = True
    with c2:
        if st.session_state.open_cam and st.button("Close Camera"):
            st.session_state.open_cam = False

    camera_img = None
    if st.session_state.open_cam:
        camera_img = st.camera_input(TEXTS["click_img"][LANG])

    src_img = camera_img if camera_img is not None else uploaded_img

    if st.button(TEXTS["run"][LANG]) and src_img is not None:
        try:
            if rf_model is None:
                st.error("Roboflow not configured on server.")
            else:
                img = Image.open(src_img).convert("RGB")
                out_img, counts = rf_predict_image_to_counts(img.copy())
                st.image(out_img, caption="Annotated", use_container_width=True)
                st.markdown(f"**{TEXTS['counts'][LANG]}:** `{counts}`")
                verdict = verdict_from_counts(counts, LANG)
                st.markdown(f"**{TEXTS['verdict'][LANG]}:** {verdict}")
                buf = io.BytesIO(); out_img.save(buf, format="PNG")
                st.download_button("Download annotated image", data=buf.getvalue(),
                                   file_name="annotated.png", mime="image/png")
        except Exception as e:
            print("Plant health error:", e, file=sys.stderr)
            st.error("Prediction failed. Please try another image.")

with colR:
    st.metric("Temperature (last)", f"{T_last:.2f} ¬∞C")
    st.metric("Rain (last)", f"{R_last:.2f} mm/hr")
    st.metric("Humidity (last)", f"{H_last:.2f} %")
    st.metric("Soil Moisture (last)", f"{S_last:.2f} %")

# =================== RICE LEAF DISEASE (server .keras + labels) ===================
st.markdown("---")
st.header(TEXTS["rice_title"][LANG])

@st.cache_resource(show_spinner=False)
def load_rice_model_and_labels():
    model, labels = None, []
    if os.path.exists(RICE_MODEL_PATH) and os.path.isfile(RICE_MODEL_PATH):
        try:
            model = tf.keras.models.load_model(RICE_MODEL_PATH, compile=False)
        except Exception as e:
            print(f"[rice] load model error from {RICE_MODEL_PATH}: {e}", file=sys.stderr)
    if os.path.exists(RICE_LABELS_PATH) and os.path.isfile(RICE_LABELS_PATH):
        try:
            with open(RICE_LABELS_PATH, "r", encoding="utf-8") as f:
                labels = [ln.strip() for ln in f if ln.strip()]
        except Exception as e:
            print(f"[rice] load labels error from {RICE_LABELS_PATH}: {e}", file=sys.stderr)
    return model, labels

def rice_preprocess_colab_style(pil_img: Image.Image, size: Tuple[int,int]=(256,256)) -> np.ndarray:
    img = pil_img.convert("RGB").resize(size, Image.BILINEAR)
    arr = np.array(img, dtype=np.float32)
    return np.expand_dims(arr, axis=0)

def to_probs(vec: np.ndarray) -> np.ndarray:
    z = np.array(vec, dtype=np.float32).reshape(-1)
    if z.size == 0:
        return z
    if (z.min() >= 0.0) and (z.max() <= 1.0) and (abs(z.sum() - 1.0) < 1e-3):
        return z
    x = z - z.max()
    e = np.exp(x)
    return e / np.sum(e)

rice_model, rice_labels = load_rice_model_and_labels()

colA, colB = st.columns([0.55, 0.45])
with colA:
    rice_img_file = st.file_uploader(TEXTS["rice_upload"][LANG], type=["jpg","jpeg","png"], key="rice_up")
    run_rice = st.button(TEXTS["rice_run"][LANG])

    if run_rice:
        if rice_model is None:
            st.error("Rice model not found. Please set RICE_MODEL_PATH to your .keras file and rerun.")
        elif rice_img_file is None:
            st.warning("Please upload an image first.")
        else:
            try:
                pil = Image.open(rice_img_file).convert("RGB")
                X = rice_preprocess_colab_style(pil, RICE_IMG_SIZE)
                raw = rice_model.predict(X, verbose=0)
                raw = np.asarray(raw)
                if raw.ndim > 1:
                    raw = raw[0]
                probs = to_probs(raw)
                top_idx = int(np.argmax(probs))
                cls_name = rice_labels[top_idx] if 0 <= top_idx < len(rice_labels) else f"class_{top_idx}"
                conf = float(probs[top_idx]) * 100.0
                st.image(pil, use_container_width=True)
                st.caption({"en":"Verdict", "hi":"‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑", "bn":"‡¶∞‡¶æ‡¶Ø‡¶º"}[LANG])
                # Render pill
                color_map = {"healthy":"#2e7d32","blight":"#c62828","smut":"#6a1b9a","brown spot":"#ef6c00"}
                def _verdict_color(lbl):
                    l = (lbl or "").lower()
                    if "healthy" in l: return "#2e7d32"
                    if "blight" in l:  return "#c62828"
                    if "smut" in l:    return "#6a1b9a"
                    if "brown" in l and "spot" in l: return "#ef6c00"
                    return "#00695c"
                def localize_rice_label(raw_label: str, lang: str) -> str:
                    RICE_VERDICT = {
                        "brown spot": {"en": "Brown Spot", "hi": "‡§¨‡•ç‡§∞‡§æ‡§â‡§® ‡§∏‡•ç‡§™‡•â‡§ü", "bn": "‡¶¨‡ßç‡¶∞‡¶æ‡¶â‡¶® ‡¶∏‡ßç‡¶™‡¶ü"},
                        "leaf smut": {"en": "Leaf Smut", "hi": "‡§≤‡•Ä‡§´ ‡§∏‡•ç‡§Æ‡§ü", "bn": "‡¶≤‡¶ø‡¶´ ‡¶∏‡ßç‡¶Æ‡¶æ‡¶ü"},
                        "bacterial leaf blight": {"en": "Bacterial Leaf Blight", "hi": "‡§¨‡•à‡§ï‡•ç‡§ü‡•Ä‡§∞‡§ø‡§Ø‡§≤ ‡§≤‡•Ä‡§´ ‡§¨‡•ç‡§≤‡§æ‡§á‡§ü", "bn": "‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ü‡ßá‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤ ‡¶≤‡¶ø‡¶´ ‡¶¨‡ßç‡¶≤‡¶æ‡¶á‡¶ü"},
                        "healthy": {"en": "Healthy", "hi": "‡§∏‡•ç‡§µ‡§∏‡•ç‡§•", "bn": "‡¶∏‡ßÅ‡¶∏‡ßç‡¶•"},
                        "normal": {"en": "Healthy", "hi": "‡§∏‡•ç‡§µ‡§∏‡•ç‡§•", "bn": "‡¶∏‡ßÅ‡¶∏‡ßç‡¶•"},
                    }
                    key = (raw_label or "").strip().lower().replace("_"," ").replace("-"," ")
                    if key in RICE_VERDICT:
                        return RICE_VERDICT[key].get(lang, RICE_VERDICT[key]["en"])
                    generic = {"en": f"Disease: {raw_label}", "hi": f"‡§∞‡•ã‡§ó: {raw_label}", "bn": f"‡¶∞‡ßã‡¶ó: {raw_label}"}
                    return generic.get(lang, f"Disease: {raw_label}")
                localized = localize_rice_label(cls_name, LANG)
                color = _verdict_color(cls_name)
                st.markdown(f"<div class='kb-verdict-pill' style='background:{color};'>{localized} ‚Äî {conf:.2f}%</div>", unsafe_allow_html=True)
                # Table
                if len(rice_labels) >= len(probs) and len(probs) > 1:
                    names = rice_labels[:len(probs)]
                    dfp = pd.DataFrame({
                        "Class": names,
                        "Confidence (%)": (probs*100.0).round(2)
                    }).sort_values("Confidence (%)", ascending=False, ignore_index=True)
                    st.dataframe(dfp, use_container_width=True)
                else:
                    st.write("Pred vector:", probs.round(4))
            except Exception as e:
                print("Rice detection error:", e, file=sys.stderr)
                st.error("Classification failed. Make sure your server model expects 256√ó256 RGB images.")
with colB:
    if rice_model is not None and len(rice_labels) > 0:
        st.caption("Rice model & labels loaded.")
    elif rice_model is not None:
        st.caption("Rice model loaded (labels optional).")
    else:
        st.caption("Set RICE_MODEL_PATH and rerun.")
'''
open(APP_PATH, "w", encoding="utf-8").write(code)
print(f"‚úÖ Wrote {APP_PATH} ({len(code.splitlines())} lines)")

# 2) Clean any prior processes
os.system("pkill -f streamlit  || true")
os.system("pkill -f ngrok      || true")

# 3) Start Streamlit in the background and show tail of its log
log_path = "/content/s.log"
proc = subprocess.Popen(
    ["streamlit", "run", APP_PATH, "--server.port", "8501", "--server.address", "0.0.0.0"],
    stdout=open(log_path, "w"), stderr=subprocess.STDOUT
)
time.sleep(5)
print("----- streamlit log tail -----")
try:
    print(pathlib.Path(log_path).read_text()[-1200:])
except Exception as e:
    print("No log yet:", e)

# 4) Open ngrok tunnel (optionally set region='in')
from pyngrok import ngrok
AUTHTOKEN = getpass.getpass("üîë Paste your ngrok auth token: ")
ngrok.set_auth_token(AUTHTOKEN)
public_url = ngrok.connect(8501, "http", bind_tls=True, options={"region":"in"}).public_url
print("\nüåç Your app is live at:", public_url, "\n")
